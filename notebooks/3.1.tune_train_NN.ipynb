{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, precision_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune and Train the NN\n",
    "Similar to the previous steps but using a little different tools from SVM and RF tuning.\n",
    "\n",
    "Feature extractors include:\n",
    "<ul>\n",
    "    <li>count vectorizer</li>\n",
    "    <li>TF-IDF vectorizer</li>\n",
    "</ul>\n",
    "\n",
    "Classifiers include:\n",
    "<ul>\n",
    "    <li>support vector machine</li>\n",
    "    <li>random forest</li>\n",
    "    <li>neural net</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "## Feature Extractors\n",
    "### Count vectorizer\n",
    "Reference: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html<br/>\n",
    "Hyperparameters to tune:\n",
    "<ul>\n",
    "    <li>ngram_range</li>\n",
    "    <li>max_df</li>\n",
    "    <li>min_df</li>\n",
    "</ul>\n",
    "\n",
    "### TF-IDF vectorizer\n",
    "Reference: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html<br/>\n",
    "Hyperparameters to tune:\n",
    "<ul>\n",
    "    <li>ngram_range</li>\n",
    "    <li>max_df</li>\n",
    "    <li>min_df</li>\n",
    "</ul>\n",
    "\n",
    "Note: Was going to tune max_features as well but forgot to put it into vectorizer call. May look at this later.\n",
    "\n",
    "## Classifiers\n",
    "### Neural Net\n",
    "Reference: This one will use tensorflow, rather than sci-kit learn. Need to still extract features with sklearn and return those vectors. Then feed them to tensorflow.<br/>\n",
    "Hyperparameters to tune:\n",
    "<ul>\n",
    "    <li>number of nodes in hidden layer</li>\n",
    "    <li>optimizer</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data and stopwords\n",
    "train_data = pd.read_pickle('../data/train_data.pkl')\n",
    "with open('../data/stopwords.pkl', 'rb') as f:\n",
    "    stopwords = pickle.load(f)\n",
    "    \n",
    "# for testing\n",
    "train_data = train_data[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TuneNeuralNet(object):\n",
    "    def __init__(self, train_data, cv_num, stopwords, title):\n",
    "        self.data = train_data\n",
    "        self.stopwords = stopwords\n",
    "        self.title = title\n",
    "        self.k_folds = KFold(n_splits=cv_num, shuffle=True)\n",
    "        self.cv_scores = pd.DataFrame()\n",
    "        \n",
    "    def tune_parameters(self, params, vector):\n",
    "        ngram_range = params['ngram_range']\n",
    "        max_df = params['max_df']\n",
    "        min_df = params['min_df']\n",
    "        \n",
    "        h1_nodes = params['h1_nodes']\n",
    "        optimizer = params['optimizer']\n",
    "\n",
    "        for n in ngram_range:\n",
    "            for mx in max_df:\n",
    "                for mn in min_df:\n",
    "                    for h1 in h1_nodes:\n",
    "                        for o in optimizer:\n",
    "                            self.run_cv(n, mx, mn, h1, o, vector)\n",
    "        return None\n",
    "\n",
    "    def save_scores_csv(self, title):\n",
    "        self.cv_scores.to_csv('../results/tuning/%s_tuning.csv' %title)\n",
    "        return None\n",
    "    \n",
    "    def run_cv(self, ngram_range, max_df, min_df, h1_nodes, optimizer, vector):\n",
    "        fold = 0\n",
    "        for train_index, val_index in self.k_folds.split(self.data):\n",
    "            fold += 1\n",
    "            print(fold)\n",
    "            X_train = self.data.iloc[train_index]['text'].values\n",
    "            y_train = self.data.iloc[train_index]['label'].values\n",
    "            X_val = self.data.iloc[val_index]['text'].values\n",
    "            y_val = self.data.iloc[val_index]['label'].values\n",
    "            \n",
    "            if vector == 'count':\n",
    "                vectorizer = CountVectorizer(ngram_range=ngram_range, \n",
    "                                             max_df=max_df, \n",
    "                                             min_df=min_df, \n",
    "                                             stop_words=self.stopwords)\n",
    "            else:\n",
    "                vectorizer = TfidfVectorizer(ngram_range=ngram_range, \n",
    "                                             max_df=max_df, \n",
    "                                             min_df=min_df, \n",
    "                                             stop_words=self.stopwords)\n",
    "            \n",
    "            try:\n",
    "                X_train_vec = vectorizer.fit_transform(X_train)\n",
    "                X_val_vec = vectorizer.transform(X_val)\n",
    "            except:\n",
    "                return None\n",
    "            else:\n",
    "                n_dim = X_train_vec.shape[1]\n",
    "                early_stopping_monitor = EarlyStopping(monitor='val_loss', patience=3)\n",
    "                \n",
    "                model = Sequential()\n",
    "                model.add(Dense(h1_nodes, activation='relu', input_dim=n_dim))\n",
    "                model.add(Dense(1, activation='sigmoid'))\n",
    "                model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) \n",
    "                history = model.fit(X_train_vec, y_train, epochs=3000, validation_split=0.2, batch_size=100, \n",
    "                                    callbacks=[early_stopping_monitor], verbose=0)\n",
    "                \n",
    "                \n",
    "                y_train_prob = model.predict(X_train_vec).flatten()\n",
    "                y_train_pred = model.predict_classes(X_train_vec).flatten()\n",
    "                train_scores = self.evaluate_cv_results(y_train, y_train_pred, y_train_prob, \n",
    "                                                        ngram_range, max_df, min_df, \n",
    "                                                        h1_nodes, optimizer)\n",
    "\n",
    "                y_val_prob = model.predict(X_val_vec).flatten()\n",
    "                y_val_pred = model.predict_classes(X_val_vec).flatten()\n",
    "                val_scores = self.evaluate_cv_results(y_val, y_val_pred, y_val_prob, \n",
    "                                                      ngram_range, max_df, min_df, \n",
    "                                                      h1_nodes, optimizer)\n",
    "\n",
    "                eval_df = self.create_scores_dataframe(train_scores, val_scores, fold, vector)\n",
    "                self.cv_scores = pd.concat([self.cv_scores, eval_df])\n",
    "                self.save_scores_csv('temp_%s' %self.title)\n",
    "        return None\n",
    "    \n",
    "    def evaluate_cv_results(self, y_true, y_pred, y_prob, ngram_range, max_df, min_df, \n",
    "                            h1_nodes, optimizer):\n",
    "        scores = {'ngram_range':[],'max_df':[],'min_df':[],'h1_nodes':[],'optimizer':[],\n",
    "                  'Acc':[],'recall':[],'PPV':[],'AUC':[]}\n",
    "\n",
    "        scores['ngram_range'].append(ngram_range)\n",
    "        scores['max_df'].append(max_df)\n",
    "        scores['min_df'].append(min_df)\n",
    "        scores['h1_nodes'].append(h1_nodes)\n",
    "        scores['optimizer'].append(optimizer)\n",
    "        scores['Acc'].append(accuracy_score(y_true, y_pred))\n",
    "        scores['recall'].append(recall_score(y_true, y_pred))\n",
    "        scores['PPV'].append(precision_score(y_true, y_pred))\n",
    "        scores['AUC'].append(roc_auc_score(y_true, y_prob))\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def create_scores_dataframe(self, train_dict, val_dict, fold, vector):\n",
    "        train_df = pd.DataFrame(train_dict)\n",
    "        train_df['dataset'] = 'train'\n",
    "        train_df['fold'] = fold\n",
    "        train_df['vector'] = vector\n",
    "\n",
    "        val_df = pd.DataFrame(val_dict)\n",
    "        val_df['dataset'] = 'val'\n",
    "        val_df['fold'] = fold\n",
    "        val_df['vector'] = vector\n",
    "        eval_df = pd.concat([train_df, val_df]).reset_index(drop=True)\n",
    "        return eval_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# nn_params = {\n",
    "#     'ngram_range':[(1,1),(1,2),(2,2)],\n",
    "#     'max_df':np.linspace(0, 1, 5),\n",
    "#     'min_df':np.linspace(0, 1, 5),\n",
    "#     'h1_nodes':[128, 512, 1024, 2048, 3200],\n",
    "#     'optimizer':['Adam','RMSprop','Adadelta']\n",
    "# }\n",
    "\n",
    "nn_params = {\n",
    "    'ngram_range':[(1,1)],\n",
    "    'max_df':[0.5],\n",
    "    'min_df':[0],\n",
    "    'h1_nodes':[128],\n",
    "    'optimizer':['Adam']\n",
    "}\n",
    "\n",
    "tune_nn = TuneNeuralNet(train_data, 3, stopwords, 'nn')\n",
    "tune_nn.tune_parameters(nn_params, 'count')\n",
    "tune_nn.tune_parameters(nn_params, 'tfidf')\n",
    "tune_nn.save_scores_csv('nn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
