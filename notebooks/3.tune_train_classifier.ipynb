{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune and Train the Classifier\n",
    "In this step, hyperparameters of the feature extractors and several classifiers will be tuned using 5-fold cross validation. The tuning will be run with a python script as this is more efficient.\n",
    "\n",
    "Feature extractors include:\n",
    "<ul>\n",
    "    <li>count vectorizer</li>\n",
    "    <li>TF-IDF vectorizer</li>\n",
    "</ul>\n",
    "\n",
    "Classifiers include:\n",
    "<ul>\n",
    "    <li>support vector machine</li>\n",
    "    <li>random forest</li>\n",
    "    <li>neural net</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "## Feature Extractors\n",
    "### Count vectorizer\n",
    "Reference: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html<br/>\n",
    "Hyperparameters to tune:\n",
    "<ul>\n",
    "    <li>ngram_range</li>\n",
    "    <li>max_df</li>\n",
    "    <li>min_df</li>\n",
    "</ul>\n",
    "\n",
    "### TF-IDF vectorizer\n",
    "Reference: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html<br/>\n",
    "Hyperparameters to tune:\n",
    "<ul>\n",
    "    <li>ngram_range</li>\n",
    "    <li>max_df</li>\n",
    "    <li>min_df</li>\n",
    "</ul>\n",
    "\n",
    "Note: Was going to tune max_features as well but forgot to put it into vectorizer call. May look at this later.\n",
    "\n",
    "## Classifiers\n",
    "### Support Vector Machine\n",
    "Reference: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html<br/>\n",
    "Hyperparameters to tune:\n",
    "<ul>\n",
    "    <li>C</li>\n",
    "    <li>kernel</li>\n",
    "    <li>degree</li>\n",
    "    <li>gamma</li>\n",
    "</ul>\n",
    "\n",
    "### Random Forest\n",
    "Reference: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html<br/>\n",
    "Hyperparameters to tune:\n",
    "<ul>\n",
    "    <li>n_estimators</li>\n",
    "    <li>criterion</li>\n",
    "    <li>max_depth</li>\n",
    "</ul>\n",
    "\n",
    "### Neural Net\n",
    "Reference: This one will use tensorflow, rather than sci-kit learn. Need to still extract features with sklearn and return those vectors. Then feed them to tensorflow.<br/>\n",
    "Hyperparameters to tune:\n",
    "<ul>\n",
    "    <li></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data and stopwords\n",
    "train_data = pd.read_pickle('../data/train_data.pkl')\n",
    "with open('../data/stopwords.pkl', 'rb') as f:\n",
    "    stopwords = pickle.load(f)\n",
    "    \n",
    "# for testing\n",
    "train_data = train_data[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: this includes max_features but not actually used in vectorization.\n",
    "\n",
    "class TuneSVM(object):\n",
    "    def __init__(self, train_data, kernel, cv_num, stopwords, title):\n",
    "        self.data = train_data\n",
    "        self.kernel = kernel\n",
    "        self.stopwords = stopwords\n",
    "        self.title = title\n",
    "        self.k_folds = KFold(n_splits=cv_num, shuffle=True)\n",
    "        self.cv_scores = pd.DataFrame()\n",
    "        \n",
    "    def tune_parameters(self, params, vector):\n",
    "        ngram_range = params['ngram_range']\n",
    "        max_df = params['max_df']\n",
    "        min_df = params['min_df']\n",
    "        max_features = params['max_features']\n",
    "        \n",
    "        C = params['C']\n",
    "\n",
    "        for n in ngram_range:\n",
    "            for mx in max_df:\n",
    "                for mn in min_df:\n",
    "                    for m in max_features:\n",
    "                        for c in C:\n",
    "                            self.run_cv(n, mx, mn, m, c, vector)\n",
    "        return None\n",
    "\n",
    "    def save_scores_csv(self, title):\n",
    "        self.cv_scores.to_csv('../results/%s_tuning.csv' %title)\n",
    "        return None\n",
    "    \n",
    "    def run_cv(self, ngram_range, max_df, min_df, max_features, C, vector):\n",
    "        fold = 0\n",
    "        for train_index, val_index in self.k_folds.split(self.data):\n",
    "            fold += 1\n",
    "            print(fold)\n",
    "            X_train = self.data.iloc[train_index]['text'].values\n",
    "            y_train = self.data.iloc[train_index]['label'].values\n",
    "            X_val = self.data.iloc[val_index]['text'].values\n",
    "            y_val = self.data.iloc[val_index]['label'].values\n",
    "            \n",
    "            if vector == 'count':\n",
    "                vectorizer = CountVectorizer(ngram_range=ngram_range, \n",
    "                                             max_df=max_df, \n",
    "                                             min_df=min_df, \n",
    "                                             stop_words=self.stopwords)\n",
    "            else:\n",
    "                vectorizer = TfidfVectorizer(ngram_range=ngram_range, \n",
    "                                             max_df=max_df, \n",
    "                                             min_df=min_df, \n",
    "                                             stop_words=self.stopwords)\n",
    "            \n",
    "            try:\n",
    "                X_train_vec = vectorizer.fit_transform(X_train)\n",
    "                X_val_vec = vectorizer.transform(X_val)\n",
    "            except:\n",
    "                return None\n",
    "            else:\n",
    "                clf = SVC(C=C, kernel=self.kernel, probability=True, gamma='scale')\n",
    "                clf.fit(X_train_vec, y_train)\n",
    "\n",
    "                y_train_pred = clf.predict(X_train_vec)\n",
    "                y_train_prob = clf.predict_proba(X_train_vec)\n",
    "                y_train_prob = y_train_prob[:, 1]\n",
    "                train_scores = self.evaluate_cv_results(y_train, y_train_pred, y_train_prob, \n",
    "                                                        ngram_range, max_df, min_df, max_features, C)\n",
    "\n",
    "                y_val_pred = clf.predict(X_val_vec)\n",
    "                y_val_prob = clf.predict_proba(X_val_vec)\n",
    "                y_val_prob = y_val_prob[:, 1]\n",
    "                val_scores = self.evaluate_cv_results(y_val, y_val_pred, y_val_prob, \n",
    "                                                      ngram_range, max_df, min_df, max_features, C)\n",
    "\n",
    "                eval_df = self.create_scores_dataframe(train_scores, val_scores, fold, vector)\n",
    "                self.cv_scores = pd.concat([self.cv_scores, eval_df])\n",
    "                self.save_scores_csv('temp_%s' %self.title)\n",
    "        return None\n",
    "    \n",
    "    def evaluate_cv_results(self, y_true, y_pred, y_prob, ngram_range, max_df, min_df, max_features, C):\n",
    "        scores = {'ngram_range':[],'max_df':[],'min_df':[],'max_features':[],'C':[],\n",
    "                  'Acc':[],'recall':[],'PPV':[],'AUC':[]}\n",
    "\n",
    "        scores['ngram_range'].append(ngram_range)\n",
    "        scores['max_df'].append(max_df)\n",
    "        scores['min_df'].append(min_df)\n",
    "        scores['max_features'].append(max_features)\n",
    "        scores['C'].append(C)\n",
    "        scores['Acc'].append(accuracy_score(y_true, y_pred))\n",
    "        scores['recall'].append(recall_score(y_true, y_pred))\n",
    "        scores['PPV'].append(precision_score(y_true, y_pred))\n",
    "        scores['AUC'].append(roc_auc_score(y_true, y_prob))\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def create_scores_dataframe(self, train_dict, val_dict, fold, vector):\n",
    "        train_df = pd.DataFrame(train_dict)\n",
    "        train_df['dataset'] = 'train'\n",
    "        train_df['fold'] = fold\n",
    "        train_df['vector'] = vector\n",
    "\n",
    "        val_df = pd.DataFrame(val_dict)\n",
    "        val_df['dataset'] = 'val'\n",
    "        val_df['fold'] = fold\n",
    "        val_df['vector'] = vector\n",
    "        eval_df = pd.concat([train_df, val_df]).reset_index(drop=True)\n",
    "        return eval_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Note: this includes max_features but not actually used in vectorization.\n",
    "\n",
    "# svm_params = {\n",
    "#     'ngram_range':[(1,1),(1,2),(2,2)],\n",
    "#     'max_df':np.linspace(0, 1, 5),\n",
    "#     'min_df':np.linspace(0, 1, 5),\n",
    "#     'max_features':[None, 1000, 2000],\n",
    "#     'C':np.linspace(0.01, 5, 5)\n",
    "# }\n",
    "\n",
    "svm_params = {\n",
    "    'ngram_range':[(1,1)],\n",
    "    'max_df':[0.5],\n",
    "    'min_df':[0],\n",
    "    'max_features':[None],\n",
    "    'C':[1.0]\n",
    "}\n",
    "\n",
    "tune_psvm = TuneSVM(train_data, 'poly', 3, stopwords, 'psvm1')\n",
    "tune_psvm.tune_parameters(svm_params, 'count')\n",
    "tune_psvm.tune_parameters(svm_params, 'tfidf')\n",
    "tune_psvm.save_scores_csv('psvm1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: this includes max_features but not actually used in vectorization.\n",
    "\n",
    "class TuneRandomForest(object):\n",
    "    def __init__(self, train_data, cv_num, stopwords, title):\n",
    "        self.data = train_data\n",
    "        self.stopwords = stopwords\n",
    "        self.title = title\n",
    "        self.k_folds = KFold(n_splits=cv_num, shuffle=True)\n",
    "        self.cv_scores = pd.DataFrame()\n",
    "        \n",
    "    def tune_parameters(self, params, vector):\n",
    "        ngram_range = params['ngram_range']\n",
    "        max_df = params['max_df']\n",
    "        min_df = params['min_df']\n",
    "        max_features = params['max_features']\n",
    "        \n",
    "        n_estimators = params['n_estimators']\n",
    "        criterion = params['criterion']\n",
    "        max_depth = params['max_depth']\n",
    "\n",
    "        for n in ngram_range:\n",
    "            for mx in max_df:\n",
    "                for mn in min_df:\n",
    "                    for m in max_features:\n",
    "                        for nest in n_estimators:\n",
    "                            for c in criterion:\n",
    "                                for mxd in max_depth:\n",
    "                                    self.run_cv(n, mx, mn, m, nest, c, mxd, vector)\n",
    "        return None\n",
    "\n",
    "    def save_scores_csv(self, title):\n",
    "        self.cv_scores.to_csv('../results/tuning/%s_tuning.csv' %title)\n",
    "        return None\n",
    "    \n",
    "    def run_cv(self, ngram_range, max_df, min_df, max_features, n_estimators, criterion, max_depth, vector):\n",
    "        fold = 0\n",
    "        for train_index, val_index in self.k_folds.split(self.data):\n",
    "            fold += 1\n",
    "            print(fold)\n",
    "            X_train = self.data.iloc[train_index]['text'].values\n",
    "            y_train = self.data.iloc[train_index]['label'].values\n",
    "            X_val = self.data.iloc[val_index]['text'].values\n",
    "            y_val = self.data.iloc[val_index]['label'].values\n",
    "            \n",
    "            if vector == 'count':\n",
    "                vectorizer = CountVectorizer(ngram_range=ngram_range, \n",
    "                                             max_df=max_df, \n",
    "                                             min_df=min_df, \n",
    "                                             stop_words=self.stopwords)\n",
    "            else:\n",
    "                vectorizer = TfidfVectorizer(ngram_range=ngram_range, \n",
    "                                             max_df=max_df, \n",
    "                                             min_df=min_df, \n",
    "                                             stop_words=self.stopwords)\n",
    "            \n",
    "            try:\n",
    "                X_train_vec = vectorizer.fit_transform(X_train)\n",
    "                X_val_vec = vectorizer.transform(X_val)\n",
    "            except:\n",
    "                return None\n",
    "            else:\n",
    "                clf = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth)\n",
    "                clf.fit(X_train_vec, y_train)\n",
    "\n",
    "                y_train_pred = clf.predict(X_train_vec)\n",
    "                y_train_prob = clf.predict_proba(X_train_vec)\n",
    "                y_train_prob = y_train_prob[:, 1]\n",
    "                train_scores = self.evaluate_cv_results(y_train, y_train_pred, y_train_prob, \n",
    "                                                        ngram_range, max_df, min_df, max_features, \n",
    "                                                        n_estimators, criterion, max_depth)\n",
    "\n",
    "                y_val_pred = clf.predict(X_val_vec)\n",
    "                y_val_prob = clf.predict_proba(X_val_vec)\n",
    "                y_val_prob = y_val_prob[:, 1]\n",
    "                val_scores = self.evaluate_cv_results(y_val, y_val_pred, y_val_prob, \n",
    "                                                      ngram_range, max_df, min_df, max_features, \n",
    "                                                      n_estimators, criterion, max_depth)\n",
    "\n",
    "                eval_df = self.create_scores_dataframe(train_scores, val_scores, fold, vector)\n",
    "                self.cv_scores = pd.concat([self.cv_scores, eval_df])\n",
    "                self.save_scores_csv('temp_%s' %self.title)\n",
    "        return None\n",
    "    \n",
    "    def evaluate_cv_results(self, y_true, y_pred, y_prob, ngram_range, max_df, min_df, max_features, \n",
    "                            n_estimators, criterion, max_depth):\n",
    "        scores = {'ngram_range':[],'max_df':[],'min_df':[],'max_features':[],'n_estimators':[],'criterion':[],\n",
    "                  'max_depth':[],'Acc':[],'recall':[],'PPV':[],'AUC':[]}\n",
    "\n",
    "        scores['ngram_range'].append(ngram_range)\n",
    "        scores['max_df'].append(max_df)\n",
    "        scores['min_df'].append(min_df)\n",
    "        scores['max_features'].append(max_features)\n",
    "        scores['n_estimators'].append(n_estimators)\n",
    "        scores['criterion'].append(criterion)\n",
    "        scores['max_depth'].append(max_depth)\n",
    "        scores['Acc'].append(accuracy_score(y_true, y_pred))\n",
    "        scores['recall'].append(recall_score(y_true, y_pred))\n",
    "        scores['PPV'].append(precision_score(y_true, y_pred))\n",
    "        scores['AUC'].append(roc_auc_score(y_true, y_prob))\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def create_scores_dataframe(self, train_dict, val_dict, fold, vector):\n",
    "        train_df = pd.DataFrame(train_dict)\n",
    "        train_df['dataset'] = 'train'\n",
    "        train_df['fold'] = fold\n",
    "        train_df['vector'] = vector\n",
    "\n",
    "        val_df = pd.DataFrame(val_dict)\n",
    "        val_df['dataset'] = 'val'\n",
    "        val_df['fold'] = fold\n",
    "        val_df['vector'] = vector\n",
    "        eval_df = pd.concat([train_df, val_df]).reset_index(drop=True)\n",
    "        return eval_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Note: this includes max_features but not actually used in vectorization.\n",
    "\n",
    "# rf_params = {\n",
    "#     'ngram_range':[(1,1),(1,2),(2,2)],\n",
    "#     'max_df':np.linspace(0, 1, 5),\n",
    "#     'min_df':np.linspace(0, 1, 5),\n",
    "#     'max_features':[None, 1000, 2000],\n",
    "#     'n_estimators':[10, 25, 50, 100, 300],\n",
    "#     'criterion':['gini','entropy'],\n",
    "#     'max_depth':[2, 10, 20, 50, 100]\n",
    "# }\n",
    "\n",
    "rf_params = {\n",
    "    'ngram_range':[(1,1)],\n",
    "    'max_df':[0.5],\n",
    "    'min_df':[0],\n",
    "    'max_features':[None],\n",
    "    'n_estimators':[10],\n",
    "    'criterion':['gini'],\n",
    "    'max_depth':[2]\n",
    "}\n",
    "\n",
    "tune_rf = TuneRandomForest(train_data, 3, stopwords, 'rf')\n",
    "tune_rf.tune_parameters(rf_params, 'count')\n",
    "tune_rf.tune_parameters(rf_params, 'tfidf')\n",
    "tune_rf.save_scores_csv('rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
