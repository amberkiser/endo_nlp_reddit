{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psaw import PushshiftAPI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Retrieval\n",
    "Get the data from reddit.\n",
    "The data is comprised of a corpus of Reddit posts. I have acquired the data from the following Reddit subreddits:\n",
    "<ul>\n",
    "    <li><a href='https://www.reddit.com/r/endometriosis/'>/r/endometriosis</a></li>\n",
    "    <li><a href='https://www.reddit.com/r/Endo/'>/r/Endo</a></li>\n",
    "    <li><a href='https://www.reddit.com/r/PCOS/'>/r/PCOS</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubmissionData(object):\n",
    "    \"\"\"\n",
    "    Retrieve submission data using psaw, a python wrapper for the Pushshit API.\n",
    "    Basic cleaning steps include:\n",
    "        - Changing [removed] to an empty space.\n",
    "        - Changing new line characters \"\\n\" to a white space.\n",
    "        - Combining title with post text.\n",
    "        - Changing time from UTC to MST.\n",
    "    \"\"\"\n",
    "    def __init__(self, api_obj, subreddit_name):\n",
    "        self.api = api_obj\n",
    "        self.subreddit_name = subreddit_name\n",
    "        self.submission_results = None\n",
    "        self.submission_df = None\n",
    "\n",
    "    def retrieve_submissions(self, limit=None):\n",
    "        if limit is not None:\n",
    "            submission_results = list(self.api.search_submissions(subreddit=self.subreddit_name,\n",
    "                                                                  filter=['title', 'selftext', 'permalink', \n",
    "                                                                          'created_utc'],\n",
    "                                                                  limit=limit))\n",
    "        else:\n",
    "            submission_results = list(self.api.search_submissions(subreddit=self.subreddit_name,\n",
    "                                                                 filter=['title', 'selftext', 'permalink', \n",
    "                                                                         'created_utc']))\n",
    "        self.submission_results = submission_results\n",
    "        return None\n",
    "\n",
    "    def submissions_to_dataframe(self):\n",
    "        sub_dict = {'title': [],\n",
    "                    'text': [],\n",
    "                    'link': [],\n",
    "                    'created_utc': []}\n",
    "\n",
    "        for post in self.submission_results:\n",
    "            try:\n",
    "                title = post.title\n",
    "                text = post.selftext\n",
    "                link = post.permalink\n",
    "                created = post.created_utc\n",
    "            except AttributeError:\n",
    "                continue\n",
    "            else:\n",
    "                sub_dict['title'].append(title)\n",
    "                sub_dict['text'].append(text)\n",
    "                sub_dict['link'].append(link)\n",
    "                sub_dict['created_utc'].append(created)\n",
    "\n",
    "        self.submission_df = pd.DataFrame(sub_dict)\n",
    "        return None\n",
    "\n",
    "    def clean_sub_data(self):\n",
    "        self.submission_df.loc[self.submission_df['text'] == '[removed]', 'text'] = ''\n",
    "        self.submission_df['text'] = self.submission_df['text'].str.replace('\\n', ' ')\n",
    "        self.submission_df['text'] = self.submission_df['title'] + ' ' + self.submission_df['text']\n",
    "        self.submission_df['type'] = 'submission'\n",
    "        self.submission_df['created_utc'] = pd.to_datetime(self.submission_df.created_utc, unit='s')\n",
    "        self.submission_df['created_mst'] = \\\n",
    "            self.submission_df.created_utc.dt.tz_localize(tz='UTC').dt.tz_convert(tz='US/Mountain')\n",
    "        self.submission_df = self.submission_df.drop(columns=['title', 'created_utc'])\n",
    "        return None\n",
    "\n",
    "    def save_sub_data(self):\n",
    "        self.submission_df.to_csv('../data/%s_sub_data.csv' % self.subreddit_name, encoding='utf-8-sig')\n",
    "        return None\n",
    "\n",
    "\n",
    "class CommentData(object):\n",
    "    \"\"\"\n",
    "    Retrieve comment data using psaw, a python wrapper for the Pushshit API. \n",
    "    Basic cleaning steps include:\n",
    "        - Changing [removed] to an empty space.\n",
    "        - Changing new line characters \"\\n\" to a white space.\n",
    "        - Changing time from UTC to MST.\n",
    "    \"\"\"\n",
    "    def __init__(self, api_obj, subreddit_name):\n",
    "        self.api = api_obj\n",
    "        self.subreddit_name = subreddit_name\n",
    "        self.comment_results = None\n",
    "        self.comment_df = None\n",
    "\n",
    "    def retrieve_comments(self, limit=None):\n",
    "        if limit is not None:\n",
    "            comment_results = list(self.api.search_comments(subreddit=self.subreddit_name,\n",
    "                                                            filter=['body', 'permalink', 'created_utc'],\n",
    "                                                            limit=limit))\n",
    "        else:\n",
    "            comment_results = list(self.api.search_comments(subreddit=self.subreddit_name,\n",
    "                                                            filter=['body', 'permalink', 'created_utc']))\n",
    "        self.comment_results = comment_results\n",
    "        return None\n",
    "\n",
    "    def comments_to_dataframe(self):\n",
    "        comm_dict = {'text': [],\n",
    "                     'link': [],\n",
    "                     'created_utc': []}\n",
    "\n",
    "        for post in self.comment_results:\n",
    "            try:\n",
    "                text = post.body\n",
    "                link = post.permalink\n",
    "                created = post.created_utc\n",
    "            except AttributeError:\n",
    "                continue\n",
    "            else:\n",
    "                comm_dict['text'].append(text)\n",
    "                comm_dict['link'].append(link)\n",
    "                comm_dict['created_utc'].append(created)\n",
    "\n",
    "        self.comment_df = pd.DataFrame(comm_dict)\n",
    "        return None\n",
    "\n",
    "    def clean_comment_data(self):\n",
    "        self.comment_df.loc[self.comment_df['text'] == '[removed]', 'text'] = ''\n",
    "        self.comment_df['text'] = self.comment_df['text'].str.replace('\\n', ' ')\n",
    "        self.comment_df['type'] = 'comment'\n",
    "        self.comment_df['created_utc'] = pd.to_datetime(self.comment_df.created_utc, unit='s')\n",
    "        self.comment_df['created_mst'] = \\\n",
    "            self.comment_df.created_utc.dt.tz_localize(tz='UTC').dt.tz_convert(tz='US/Mountain')\n",
    "        self.comment_df = self.comment_df.drop(columns=['created_utc'])\n",
    "        return None\n",
    "\n",
    "    def save_comment_data(self):\n",
    "        self.comment_df.to_csv('../data/%s_comment_data.csv' % self.subreddit_name, \n",
    "                               encoding='utf-8-sig')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = PushshiftAPI()\n",
    "\n",
    "endo_sub = SubmissionData(api, 'Endo')\n",
    "endo_sub.retrieve_submissions()\n",
    "endo_sub.submissions_to_dataframe()\n",
    "endo_sub.clean_sub_data()\n",
    "endo_sub.save_sub_data()\n",
    "\n",
    "endometriosis_sub = SubmissionData(api, 'endometriosis')\n",
    "endometriosis_sub.retrieve_submissions()\n",
    "endometriosis_sub.submissions_to_dataframe()\n",
    "endometriosis_sub.clean_sub_data()\n",
    "endometriosis_sub.save_sub_data()\n",
    "\n",
    "PCOS_sub = SubmissionData(api, 'PCOS')\n",
    "PCOS_sub.retrieve_submissions()\n",
    "PCOS_sub.submissions_to_dataframe()\n",
    "PCOS_sub.clean_sub_data()\n",
    "PCOS_sub.save_sub_data()\n",
    "\n",
    "endo_com = CommentData(api, 'Endo')\n",
    "endo_com.retrieve_comments(limit=10000)\n",
    "endo_com.comments_to_dataframe()\n",
    "endo_com.clean_comment_data()\n",
    "endo_com.save_comment_data()\n",
    "\n",
    "endometriosis_com = CommentData(api, 'endometriosis')\n",
    "endometriosis_com.retrieve_comments(limit=10000)\n",
    "endometriosis_com.comments_to_dataframe()\n",
    "endometriosis_com.clean_comment_data()\n",
    "endometriosis_com.save_comment_data()\n",
    "\n",
    "PCOS_com = CommentData(api, 'PCOS')\n",
    "PCOS_com.retrieve_comments(limit=10000)\n",
    "PCOS_com.comments_to_dataframe()\n",
    "PCOS_com.clean_comment_data()\n",
    "PCOS_com.save_comment_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: See scripts in \"1.data_retrieval\" folder for scripting implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
