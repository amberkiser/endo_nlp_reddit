{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data for classifier training\n",
    "This includes assigning labels to the data and splitting the data into training and testing sets.\n",
    "\n",
    "Most of the data cleaning will be performed in the feature extraction step using sklearn. This includes making all words lowercase, removing punctuation, removing non-alphabet characters (including numbers and emojis), and removing stopwords. This step will be part of the training/tuning phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "endometriosis_sub_posts = pd.read_csv('../data/endometriosis_sub_data.csv')\n",
    "endometriosis_com_posts = pd.read_csv('../data/endometriosis_comment_data.csv')\n",
    "endo_sub_posts = pd.read_csv('../data/Endo_sub_data.csv')\n",
    "endo_com_posts = pd.read_csv('../data/Endo_comment_data.csv')\n",
    "endo_posts = pd.concat([endometriosis_sub_posts, endometriosis_com_posts, endo_sub_posts, endo_com_posts])\n",
    "endo_posts = endo_posts.loc[~endo_posts['text'].isna()].reset_index(drop=True)\n",
    "\n",
    "pcos_sub_posts = pd.read_csv('../data/PCOS_sub_data.csv')\n",
    "pcos_com_posts = pd.read_csv('../data/PCOS_comment_data.csv')\n",
    "pcos_posts = pd.concat([pcos_sub_posts, pcos_com_posts])\n",
    "pcos_posts = pcos_posts.loc[~pcos_posts['text'].isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use NLTK stopwords plus some additional curated stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "more_stopwords = ['endo','endometriosis','pcos','polycystic','also','one','time','even','symptom','symptoms','know',\n",
    "                  'like','think','though','really','would','still','going','thing','doctor','get',\"i'm\",\"i've\",'said',\n",
    "                  'want','told','could','thought','lot','that','since','say','thank']\n",
    "stop_words.extend(more_stopwords)\n",
    "stop_words = set(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 39464 endometriosis-related posts.\n",
      "There are 37204 PCOS-related posts.\n"
     ]
    }
   ],
   "source": [
    "print('There are %d endometriosis-related posts.' %len(endo_posts))\n",
    "print('There are %d PCOS-related posts.' %len(pcos_posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "endo_posts['label'] = 1\n",
    "pcos_posts['label'] = 0\n",
    "\n",
    "all_posts = pd.concat([endo_posts, pcos_posts]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(all_posts, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[['text','label']].reset_index(drop=True)\n",
    "test_data = test_data[['text','label']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data sets and stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_pickle('../data/train_data.pkl')\n",
    "test_data.to_pickle('../data/test_data.pkl')\n",
    "\n",
    "with open('../data/stopwords.pkl', 'wb') as f:\n",
    "    pickle.dump(list(stop_words), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
