{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, precision_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import load\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and stopwords\n",
    "test_data = pd.read_pickle('../data/test_data.pkl')\n",
    "\n",
    "with open('../data/stopwords.pkl', 'rb') as f:\n",
    "    stopwords = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = {\n",
    "    'count_model': load('../results/models/Count-SVM_model.joblib'),\n",
    "    'count_test': load('../data/Count-SVM_test_vec.joblib'),\n",
    "    'tfidf_model': load('../results/models/TF-IDF-SVM_model.joblib'),\n",
    "    'tfidf_test': load('../data/TF-IDF-SVM_test_vec.joblib')\n",
    "}\n",
    "\n",
    "rf = {\n",
    "    'count_model': load('../results/models/Count-RF_model.joblib'),\n",
    "    'count_test': load('../data/Count-RF_test_vec.joblib'),\n",
    "    'tfidf_model': load('../results/models/TF-IDF-RF_model.joblib'),\n",
    "    'tfidf_test': load('../data/TF-IDF-RF_test_vec.joblib')\n",
    "}\n",
    "\n",
    "nn = {\n",
    "    'count_model': load_model('../results/models/Count-NN_model.h5'),\n",
    "    'count_test': load('../data/Count-NN_test_vec.joblib'),\n",
    "    'tfidf_model': load_model('../results/models/TF-IDF-NN_model.h5'),\n",
    "    'tfidf_test': load('../data/TF-IDF-NN_test_vec.joblib')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompareModels(object):\n",
    "    def __init__(self, test_data, svm_dict, rf_dict, nn_dict):\n",
    "        self.test_data = test_data\n",
    "        self.svm_params = svm_dict\n",
    "        self.rf_params = rf_dict\n",
    "        self.nn_params = nn_dict\n",
    "        self.scores = pd.DataFrame()\n",
    "    \n",
    "    def plot_roc_curves(self):\n",
    "        fpr_svm_count, tpr_svm_count = self.get_fpr_tpr(self.svm_params['count_model'], self.svm_params['count_test'])\n",
    "        fpr_svm_tfidf, tpr_svm_tfidf = self.get_fpr_tpr(self.svm_params['tfidf_model'], self.svm_params['tfidf_test'])\n",
    "        \n",
    "        fpr_rf_count, tpr_rf_count = self.get_fpr_tpr(self.rf_params['count_model'], self.rf_params['count_test'])\n",
    "        fpr_rf_tfidf, tpr_rf_tfidf = self.get_fpr_tpr(self.rf_params['tfidf_model'], self.rf_params['tfidf_test'])\n",
    "        \n",
    "        fpr_nn_count, tpr_nn_count = self.get_fpr_tpr_keras(self.nn_params['count_model'], \n",
    "                                                            self.nn_params['count_test'])\n",
    "        fpr_nn_tfidf, tpr_nn_tfidf = self.get_fpr_tpr_keras(self.nn_params['tfidf_model'], \n",
    "                                                            self.nn_params['tfidf_test'])\n",
    "    \n",
    "        plt.figure(figsize=(12, 10))\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--', color='#D3D3D3')\n",
    "        plt.plot(fpr_svm_count, tpr_svm_count, color='#fadbd8', label='Count-SVM') # light red\n",
    "        plt.plot(fpr_svm_tfidf, tpr_svm_tfidf, color='#943126', label='TF-IDF-SVM') # dark red\n",
    "        plt.plot(fpr_rf_count, tpr_rf_count, color='#ebdef0', label='Count-RF') # light purple\n",
    "        plt.plot(fpr_rf_tfidf, tpr_rf_tfidf, color='#512e5f', label='TF-IDF-RF') # dark purple\n",
    "        plt.plot(fpr_nn_count, tpr_nn_count, color='#d6eaf8', label='Count-NN') # light blue\n",
    "        plt.plot(fpr_nn_tfidf, tpr_nn_tfidf, color='#21618c', label='TF-IDF-NN') # dark blue\n",
    "        plt.title('Receiver Operating Characteristic Curves', fontsize=20)\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend()\n",
    "        plt.savefig('../results/images/all_ROC_curve.png', bbox_inches='tight')\n",
    "        return None\n",
    "    \n",
    "    def get_fpr_tpr(self, clf, X_vec):\n",
    "        y_test = self.test_data['label'].values\n",
    "        y_prob = clf.predict_proba(X_vec)\n",
    "        y_prob = y_prob[:, 1]\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "        return fpr, tpr\n",
    "    \n",
    "    def get_fpr_tpr_keras(self, model, X_vec):\n",
    "        y_test = self.test_data['label'].values\n",
    "        y_prob = model.predict(X_vec).flatten()\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "        return fpr, tpr\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models = CompareModels(test_data, svm, rf, nn)\n",
    "compare_models.plot_roc_curves()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importances\n",
    "This will find the importance of each feature within the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle('../data/train_data.pkl')\n",
    "X_train = train_data['text'].values\n",
    "test_data = pd.read_pickle('../data/test_data.pkl')\n",
    "X_test = train_data['text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_range = (1,1)\n",
    "max_df = 1.0\n",
    "min_df = 0\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=ngram_range, \n",
    "                             max_df=max_df, \n",
    "                             min_df=min_df, \n",
    "                             stop_words=stopwords)\n",
    "\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "names = vectorizer.get_feature_names()\n",
    "feature_importances = rf['count_model'].feature_importances_\n",
    "\n",
    "fi_df = pd.DataFrame({'token':names, 'importance': feature_importances})\n",
    "count_top = fi_df.sort_values('importance', ascending=False).head(10).sort_values('importance', ascending=True)\n",
    "\n",
    "\n",
    "ngram_range = (1,1)\n",
    "max_df = 0.5\n",
    "min_df = 0\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=ngram_range, \n",
    "                             max_df=max_df, \n",
    "                             min_df=min_df, \n",
    "                             stop_words=stopwords)\n",
    "\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "names = vectorizer.get_feature_names()\n",
    "feature_importances = rf['tfidf_model'].feature_importances_\n",
    "\n",
    "fi_df = pd.DataFrame({'token':names, 'importance': feature_importances})\n",
    "tfidf_top = fi_df.sort_values('importance', ascending=False).head(10).sort_values('importance', ascending=True)\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,8))\n",
    "fig.suptitle('Feature Importances of Random Forest Models', size=20)\n",
    "fig.add_subplot(frame_on=False)\n",
    "plt.tick_params(labelcolor='none', bottom=False, left=False)\n",
    "plt.xlabel('Feature Importance', size=12)\n",
    "ax1.barh(y=count_top['token'].values, width=count_top['importance'].values)\n",
    "ax1.set_ylabel('Feature', size=15)\n",
    "ax1.tick_params(axis='y', which='major', labelsize=13)\n",
    "ax1.tick_params(axis='x', which='major', labelsize=10)\n",
    "ax2.barh(y=tfidf_top['token'].values, width=tfidf_top['importance'].values)\n",
    "ax2.tick_params(axis='y', which='major', labelsize=13)\n",
    "ax2.tick_params(axis='x', which='major', labelsize=10)\n",
    "ax1.set_title('Count', size=15)\n",
    "ax2.set_title('TF-IDF', size=15)\n",
    "fig.subplots_adjust(wspace=0.25)\n",
    "plt.savefig('../results/images/rf_feature_importance.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_range = (1,2)\n",
    "max_df = 0.5\n",
    "min_df = 0\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=ngram_range, \n",
    "                             max_df=max_df, \n",
    "                             min_df=min_df, \n",
    "                             stop_words=stopwords)\n",
    "\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "names = vectorizer.get_feature_names()\n",
    "coef = svm['count_model'].coef_.toarray().flatten()\n",
    "fi_df = pd.DataFrame({'token':names, 'importance': coef})\n",
    "\n",
    "pos = fi_df.sort_values('importance', ascending=False).head(5).sort_values('importance', ascending=True)\n",
    "neg = fi_df.sort_values('importance', ascending=True).head(5)\n",
    "\n",
    "count_top = pd.concat([neg, pos])\n",
    "\n",
    "\n",
    "ngram_range = (1,2)\n",
    "max_df = 0.25\n",
    "min_df = 0\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=ngram_range, \n",
    "                             max_df=max_df, \n",
    "                             min_df=min_df, \n",
    "                             stop_words=stopwords)\n",
    "\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "names = vectorizer.get_feature_names()\n",
    "coef = svm['tfidf_model'].coef_.toarray().flatten()\n",
    "fi_df = pd.DataFrame({'token':names, 'importance': coef})\n",
    "\n",
    "pos = fi_df.sort_values('importance', ascending=False).head(5).sort_values('importance', ascending=True)\n",
    "neg = fi_df.sort_values('importance', ascending=True).head(5)\n",
    "\n",
    "tfidf_top = pd.concat([neg, pos])\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,8))\n",
    "fig.suptitle('Feature Importances of SVM Models', size=20)\n",
    "fig.add_subplot(frame_on=False)\n",
    "plt.tick_params(labelcolor='none', bottom=False, left=False)\n",
    "plt.xlabel('Feature Importance', size=12)\n",
    "ax1.barh(y=count_top['token'].values, width=count_top['importance'].values)\n",
    "ax1.set_ylabel('Feature', size=15)\n",
    "ax1.tick_params(axis='y', which='major', labelsize=13)\n",
    "ax1.tick_params(axis='x', which='major', labelsize=10)\n",
    "ax2.barh(y=tfidf_top['token'].values, width=tfidf_top['importance'].values)\n",
    "ax2.tick_params(axis='y', which='major', labelsize=13)\n",
    "ax2.tick_params(axis='x', which='major', labelsize=10)\n",
    "ax1.set_title('Count', size=15)\n",
    "ax2.set_title('TF-IDF', size=15)\n",
    "fig.subplots_adjust(wspace=0.3)\n",
    "plt.savefig('../results/images/svm_feature_importance.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net\n",
    "This gets more complicated here as you have additional layers with different weights. Advanced methods must be used to understand what is happening in this model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
